"use strict";(self.webpackChunkdefang_docs=self.webpackChunkdefang_docs||[]).push([[6380],{28453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>i});var o=n(96540);const r={},a=o.createContext(r);function s(e){const t=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(a.Provider,{value:t},e.children)}},31526:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});var o=n(74848),r=n(28453);const a={title:"Sample: Starter Kit for RAG + Agents with CrewAI",description:"Going over our sample for RAG + Agents with CrewAI",slug:"rag-agents-crewai-sample",tags:["Cloud","NoDevOps","Docker Compose","Defang","Sample"],author:"Defang Team"},s=void 0,i={permalink:"/blog/rag-agents-crewai-sample",source:"@site/blog/2025-06-16-crew-ai-sample.md",title:"Sample: Starter Kit for RAG + Agents with CrewAI",description:"Going over our sample for RAG + Agents with CrewAI",date:"2025-06-16T00:00:00.000Z",formattedDate:"June 16, 2025",tags:[{label:"Cloud",permalink:"/blog/tags/cloud"},{label:"NoDevOps",permalink:"/blog/tags/no-dev-ops"},{label:"Docker Compose",permalink:"/blog/tags/docker-compose"},{label:"Defang",permalink:"/blog/tags/defang"},{label:"Sample",permalink:"/blog/tags/sample"}],readingTime:6.27,hasTruncateMarker:!1,authors:[{name:"Defang Team"}],frontMatter:{title:"Sample: Starter Kit for RAG + Agents with CrewAI",description:"Going over our sample for RAG + Agents with CrewAI",slug:"rag-agents-crewai-sample",tags:["Cloud","NoDevOps","Docker Compose","Defang","Sample"],author:"Defang Team"},unlisted:!1,prevItem:{title:"June 2025 Defang Compose Update",permalink:"/blog/2025-07-10-product-update"},nextItem:{title:"Bridging Local Development and Cloud Deployment",permalink:"/blog/defang-docker-compose"}},l={authorsImageUrls:[void 0]},d=[{value:"Why Build a Starter Kit for RAG + Agents?",id:"why-build-a-starter-kit-for-rag--agents",level:2},{value:"A Demo in 60 Seconds",id:"a-demo-in-60-seconds",level:2},{value:"Architecture at a Glance",id:"architecture-at-a-glance",level:2},{value:"Under the Hood: The Services",id:"under-the-hood-the-services",level:2},{value:"Django + Channels",id:"django--channels",level:3},{value:"PostgreSQL + pgvector",id:"postgresql--pgvector",level:3},{value:"Redis",id:"redis",level:3},{value:"Celery Worker",id:"celery-worker",level:3},{value:"LLM and Embedding Services",id:"llm-and-embedding-services",level:3},{value:"CrewAI Workflows",id:"crewai-workflows",level:3},{value:"How the Compose Files Work",id:"how-the-compose-files-work",level:2},{value:"The Three-Step Deployment Journey",id:"the-three-step-deployment-journey",level:2},{value:"Some Best Practices and Design Choices",id:"some-best-practices-and-design-choices",level:2},{value:"Going Further: Extending the Sample",id:"going-further-extending-the-sample",level:2},{value:"Ready to Build?",id:"ready-to-build",level:2}];function c(e){const t={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h2,{id:"why-build-a-starter-kit-for-rag--agents",children:"Why Build a Starter Kit for RAG + Agents?"}),"\n",(0,o.jsxs)(t.p,{children:["Let\u2019s be honest: every developer who\u2019s played with LLMs gets that rush of \u201cwow\u201d from the first working demo. But the real headaches show up when you need to stitch LLMs into something production-grade: an app that can pull in real data, coordinate multi-step logic, and more. Suddenly, you\u2019re not just writing single prompts. You\u2019re coordinating between multiple prompts, managing queues, adding vector databases, orchestrating workers, and trying to get things back to the user in real-time. We've found that ",(0,o.jsx)(t.a,{href:"https://www.crewai.com/",children:"CrewAI"})," (coordinating prompts, agents, tools) + ",(0,o.jsx)(t.a,{href:"https://www.djangoproject.com/",children:"Django"})," (building an api, managing data), with a bit of ",(0,o.jsx)(t.a,{href:"https://docs.celeryproject.org/en/stable/",children:"Celery"})," (orchestrating workers/async tasks), is a really nice set of tools for this. We're also going to use ",(0,o.jsx)(t.a,{href:"https://channels.readthedocs.io/en/stable/",children:"Django Channels"})," (real-time updates) to push updates back to the user. And of course, we'll use ",(0,o.jsx)(t.a,{href:"https://www.defang.io/",children:"Defang"})," to deploy all that to the cloud."]}),"\n",(0,o.jsx)(t.p,{children:"If this sounds familiar (or if you're dreading the prospect of dealing with it), you\u2019re the target audience for this sample. Instead of slogging through weeks of configuration and permissions hell, you get a ready-made template that runs on your laptop, then scales\u2014unchanged\u2014to Defang\u2019s Playground, and finally to your own AWS or GCP account. All the gnarly infra is abstracted, so you can focus on getting as much value as possible out of that magical combo of CrewAI and Django."}),"\n",(0,o.jsx)(t.admonition,{title:"Just want the sample?",type:"info",children:(0,o.jsxs)(t.p,{children:["You can ",(0,o.jsx)(t.a,{href:"https://github.com/DefangSamples/sample-crew-django-redis-postgres-template",children:"find it here"}),"."]})}),"\n",(0,o.jsx)(t.h2,{id:"a-demo-in-60-seconds",children:"A Demo in 60 Seconds"}),"\n",(0,o.jsx)(t.p,{children:"Imagine you're building a system. It might use multiple LLM calls. It might do complex, branching logic in its prompts. It might need to store embeddings to retrieve things in the future, either to pull them into a prompt, or to return them outright. It might need to store other records that don't have embeddings. Here's a very lightweight version of a system like that, as a starting point:"}),"\n",(0,o.jsx)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/0YlDcUSfdcc?si=afue_MwrWs2-ZNBV",title:"Quick Demo",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:!0}),"\n",(0,o.jsx)(t.h2,{id:"architecture-at-a-glance",children:"Architecture at a Glance"}),"\n",(0,o.jsxs)(t.p,{children:["Behind the scenes, the workflow is clean and powerful. The browser connects via ",(0,o.jsx)(t.a,{href:"https://channels.readthedocs.io/en/latest/deploying.html#http-and-websocket",children:"WebSockets to our app using Django Channels"}),". Heavy work is pushed to a ",(0,o.jsx)(t.a,{href:"https://docs.celeryq.dev/en/stable/",children:"Celery worker"}),". That worker generates an ",(0,o.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Embedding_(machine_learning)",children:"embedding"}),", checks ",(0,o.jsx)(t.a,{href:"https://www.postgresql.org/",children:"Postgres"})," with ",(0,o.jsx)(t.a,{href:"https://github.com/pgvector/pgvector",children:"pgvector"})," for a match, and either returns the summary or, if there\u2019s no hit, fires up a ",(0,o.jsx)(t.a,{href:"https://www.crewai.com/",children:"CrewAI agent"})," to generate one. Every update streams back through ",(0,o.jsx)(t.a,{href:"https://redis.io/",children:"Redis"})," and Django Channels so users get progress in real time."]}),"\n",(0,o.jsx)("img",{src:"/img/crew-ai-sample/arch.png",alt:"Architecture",style:{boxShadow:"none",borderRadius:"0",width:"100%",maxWidth:"650px",height:"auto"}}),"\n",(0,o.jsxs)(t.p,{children:["Durable state lives in Postgres and Redis. Model services (",(0,o.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/LLM",children:"LLMs"})," and embeddings) are fully swappable, so you can upgrade to different models in the cloud or localize with the ",(0,o.jsx)(t.a,{href:"https://docs.docker.com/compose/how-tos/model-runner/",children:"Docker Model Runner"})," without rewriting the full stack."]}),"\n",(0,o.jsx)(t.h2,{id:"under-the-hood-the-services",children:"Under the Hood: The Services"}),"\n",(0,o.jsx)(t.h3,{id:"django--channels",children:"Django + Channels"}),"\n",(0,o.jsxs)(t.p,{children:["The Django app is the front door, routing HTTP and WebSocket traffic, serving up the admin, and delivering static content. It\u2019s built on ",(0,o.jsx)(t.a,{href:"https://github.com/django/daphne",children:"Daphne"})," and Django Channels, with Redis as the channel layer for real-time group events. Django\u2019s admin is your friend here: to start you can check what summaries exist, but if you start building out your own app, it'll make it a breeze to debug and manage your system."]}),"\n",(0,o.jsx)(t.h3,{id:"postgresql--pgvector",children:"PostgreSQL + pgvector"}),"\n",(0,o.jsx)(t.p,{children:"This is where your data lives. Summaries and their 1024-dimension embeddings go here. A simple SQL query checks for close matches by cosine distance, and pgvector\u2019s index keeps search blazing fast. In BYOC (bring-your-own-cloud) mode, flip a single flag and Defang provisions you a production-grade RDS instance."}),"\n",(0,o.jsx)(t.h3,{id:"redis",children:"Redis"}),"\n",(0,o.jsx)(t.p,{children:"Redis is doing triple duty: as the message broker and result backend for Celery, and as the channel layer for real-time WebSocket updates. The pub/sub system lets a single worker update all browser tabs listening to the same group. And if you want to scale up, swap a flag and Defang will run managed ElastiCache in production. No code change required."}),"\n",(0,o.jsx)(t.h3,{id:"celery-worker",children:"Celery Worker"}),"\n",(0,o.jsx)(t.p,{children:"The Celery worker is where the magic happens. It takes requests off the queue, generates embeddings, checks for similar summaries, and\u2014if necessary\u2014invokes a CrewAI agent to get a new summary. It then persists summaries and pushes progress updates back to the user."}),"\n",(0,o.jsx)(t.h3,{id:"llm-and-embedding-services",children:"LLM and Embedding Services"}),"\n",(0,o.jsxs)(t.p,{children:["Thanks to Docker Model Runner, the LLM and embedding services run as containerized, OpenAI-compatible HTTP endpoints. Want to switch to a different model? Change a single line in your compose file. Environment variables like ",(0,o.jsx)(t.code,{children:"LLM_URL"})," and ",(0,o.jsx)(t.code,{children:"EMBEDDING_MODEL"})," are injected for you\u2014no secret sharing or hard-coding required."]}),"\n",(0,o.jsx)(t.h3,{id:"crewai-workflows",children:"CrewAI Workflows"}),"\n",(0,o.jsx)(t.p,{children:"With CrewAI, your agent logic is declarative and pluggable. This sample keeps it simple\u2014a single summarization agent\u2014but you can add classification, tool-calling, or chain-of-thought logic without rewriting your task runner."}),"\n",(0,o.jsx)(t.h2,{id:"how-the-compose-files-work",children:"How the Compose Files Work"}),"\n",(0,o.jsxs)(t.p,{children:["In local dev, your ",(0,o.jsx)(t.code,{children:"compose.local.yaml"})," spins up ",(0,o.jsx)(t.a,{href:"https://hub.docker.com/r/ai/gemma3",children:"Gemma"})," and ",(0,o.jsx)(t.a,{href:"https://hub.docker.com/r/ai/mxbai-embed-large",children:"Mixedbread"})," models, running fully locally and with no cloud credentials or API keys required. URLs for service-to-service communication are injected at runtime. When you\u2019re ready to deploy, swap in the main ",(0,o.jsx)(t.code,{children:"compose.yaml"})," which adds Defang\u2019s ",(0,o.jsx)(t.code,{children:"x-defang-llm"}),", ",(0,o.jsx)(t.code,{children:"x-defang-redis"}),", and ",(0,o.jsx)(t.code,{children:"x-defang-postgres"})," flags. Now, Defang maps your Compose intent to real infrastructure\u2014managed model endpoints, Redis, and Postgres\u2014on cloud providers like AWS or GCP. It handles all networking, secrets, and service discovery for you. There\u2019s no YAML rewriting or \u201cdev vs prod\u201d drift."]}),"\n",(0,o.jsx)(t.h2,{id:"the-three-step-deployment-journey",children:"The Three-Step Deployment Journey"}),"\n",(0,o.jsxs)(t.p,{children:["You can run everything on your laptop with a single ",(0,o.jsx)(t.code,{children:"docker compose -f ./compose.local.yaml up"})," command\u2014no cloud dependencies, fast iteration, and no risk of cloud charges. When you\u2019re ready for the next step, use ",(0,o.jsx)(t.code,{children:"defang compose up"})," to push to the Defang Playground. This free hosted sandbox is perfect for trying Defang, demos, or prototyping. It automatically adds TLS to your endpoints and sleeps after a week. For production, use your own AWS or GCP account. ",(0,o.jsx)(t.code,{children:"DEFANG_PROVIDER=aws defang compose up"})," maps each service to a managed equivalent (ECS, RDS, ElastiCache, Bedrock models), wires up secrets, networking, etc. Your infra. Your data."]}),"\n",(0,o.jsx)(t.h2,{id:"some-best-practices-and-design-choices",children:"Some Best Practices and Design Choices"}),"\n",(0,o.jsx)(t.p,{children:"This sample uses vector similarity to try and fetch summaries that are semantically similar to the input. For more robust results, you might want to embed the original input. You can also think about chunking up longer content for finer-grained matches that you can integrate in your CrewAI workflows. Real-time progress via Django Channels beats HTTP polling, especially for LLM tasks that can take a while. The app service is stateless, which means you can scale it horizontally just by adding more containers which is easy to specify in your compose file."}),"\n",(0,o.jsx)(t.h2,{id:"going-further-extending-the-sample",children:"Going Further: Extending the Sample"}),"\n",(0,o.jsx)(t.p,{children:"You\u2019re not limited to a single summarization agent. CrewAI makes it trivial to add multi-agent flows (classification, tool use, knowledge retrieval). For big docs, chunk-level embeddings allow granular retrieval. You can wire in tool-calling to connect with external APIs or databases. You can integrate more deeply with Django's ORM and the PGVector tooling that we demo'd in the sample to build more complex agents that actually use RAG."}),"\n",(0,o.jsx)(t.h2,{id:"ready-to-build",children:"Ready to Build?"}),"\n",(0,o.jsx)(t.p,{children:"With this sample, you\u2019ve got an agent-ready, RAG-ready backend that runs anywhere, with no stacks of YAML or vendor lock-in. Fork it, extend it, productionize it: scale up, add more agents, or swap in different models, or more models!"}),"\n",(0,o.jsx)(t.p,{children:"Quickstart:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-shell",children:"# Local\ndocker compose -f compose.local.yaml up --build\n# Playground\ndefang compose up\n# BYOC\n# Setup credentials and then swap <provider> with aws or gcp\nDEFANG_PROVIDER=<provider> defang compose up\n"})}),"\n",(0,o.jsxs)(t.p,{children:["Want more? File an ",(0,o.jsx)(t.a,{href:"https://github.com/DefangLabs/samples/issues",children:"issue"})," to request a sample\u2014we'll do everything we can to help you deploy better and faster!"]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);