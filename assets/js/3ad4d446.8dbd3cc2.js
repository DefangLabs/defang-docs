"use strict";(self.webpackChunkdefang_docs=self.webpackChunkdefang_docs||[]).push([[5321],{28453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>r});var o=s(96540);const t={},a=o.createContext(t);function i(e){const n=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),o.createElement(a.Provider,{value:n},e.children)}},95252:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"tutorials/deploy-openai-apps/aws-bedrock","title":"AWS Bedrock","description":"Deploy OpenAI Apps to AWS Bedrock using Defang.","source":"@site/docs/tutorials/deploy-openai-apps/aws-bedrock.mdx","sourceDirName":"tutorials/deploy-openai-apps","slug":"/tutorials/deploy-openai-apps/aws-bedrock","permalink":"/docs/tutorials/deploy-openai-apps/aws-bedrock","draft":false,"unlisted":false,"editUrl":"https://github.com/DefangLabs/defang-docs/tree/main/docs/tutorials/deploy-openai-apps/aws-bedrock.mdx","tags":[],"version":"current","frontMatter":{"title":"AWS Bedrock","description":"Deploy OpenAI Apps to AWS Bedrock using Defang."},"sidebar":"tutorialsSidebar","previous":{"title":"Deploy OpenAI Apps on Managed LLMs","permalink":"/docs/tutorials/deploy-openai-apps/"},"next":{"title":"GCP Vertex AI","permalink":"/docs/tutorials/deploy-openai-apps/gcp-vertex"}}');var t=s(74848),a=s(28453);s(96540);const i={title:"AWS Bedrock",description:"Deploy OpenAI Apps to AWS Bedrock using Defang."},r="Deploy OpenAI Apps to AWS Bedrock",l={},c=[{value:"Add an LLM Service to Your Compose File",id:"add-an-llm-service-to-your-compose-file",level:2},{value:"Notes:",id:"notes",level:3},{value:"Redirect Application Traffic",id:"redirect-application-traffic",level:2},{value:"Selecting a Model",id:"selecting-a-model",level:2},{value:"Complete Example Compose File",id:"complete-example-compose-file",level:2},{value:"Environment Variable Matrix",id:"environment-variable-matrix",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"deploy-openai-apps-to-aws-bedrock",children:"Deploy OpenAI Apps to AWS Bedrock"})}),"\n",(0,t.jsxs)(n.p,{children:["Let's assume you have an app that uses an OpenAI client library and you want to deploy it to the cloud on ",(0,t.jsx)(n.strong,{children:"AWS Bedrock"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["This tutorial shows you how ",(0,t.jsx)(n.strong,{children:"Defang"})," makes it easy."]}),"\n",(0,t.jsxs)(n.p,{children:["Suppose you start with a ",(0,t.jsx)(n.code,{children:"compose.yaml"})," file with one ",(0,t.jsx)(n.code,{children:"app"})," service, like this:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'services:\n  app:\n    build:\n      context: .\n    ports:\n      - 3000:3000\n    environment:\n      OPENAI_API_KEY:\n    healthcheck:\n      test: ["CMD", "curl", "-f", "http://localhost:3000/"]\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"add-an-llm-service-to-your-compose-file",children:"Add an LLM Service to Your Compose File"}),"\n",(0,t.jsxs)(n.p,{children:["You can use AWS Bedrock without changing your ",(0,t.jsx)(n.code,{children:"app"})," code by introducing a new ",(0,t.jsx)(n.a,{href:"https://github.com/DefangLabs/openai-access-gateway",children:(0,t.jsx)(n.code,{children:"defangio/openai-access-gateway"})})," service. We'll call the new service ",(0,t.jsx)(n.code,{children:"llm"}),". This new service will act as a proxy between your application and AWS Bedrock, and will transparently handle converting your OpenAI requests into AWS Bedrock requests and Bedrock responses into OpenAI responses. This allows you to use AWS Bedrock with your existing OpenAI client SDK."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-diff",children:"+  llm:\n+    image: defangio/openai-access-gateway\n+    x-defang-llm: true\n+    ports:\n+      - target: 80\n+        published: 80\n+        mode: host\n+    environment:\n+      - OPENAI_API_KEY\n+      - REGION\n"})}),"\n",(0,t.jsx)(n.h3,{id:"notes",children:"Notes:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The container image is based on ",(0,t.jsx)(n.a,{href:"https://github.com/aws-samples/bedrock-access-gateway",children:"aws-samples/bedrock-access-gateway"}),", with enhancements."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"x-defang-llm: true"})," signals to ",(0,t.jsx)(n.strong,{children:"Defang"})," that this service should be configured to use target platform AI services."]}),"\n",(0,t.jsxs)(n.li,{children:["New environment variables:","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"REGION"})," is the zone where the services runs (for AWS, this is the equivalent of AWS_REGION)"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.admonition,{type:"tip",children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"OpenAI Key"})}),(0,t.jsx)(n.p,{children:"You no longer need your original OpenAI API Key.\nWe recommend generating a random secret for authentication with the gateway:"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"defang config set OPENAI_API_KEY --random\n"})})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"redirect-application-traffic",children:"Redirect Application Traffic"}),"\n",(0,t.jsxs)(n.p,{children:["Modify your ",(0,t.jsx)(n.code,{children:"app"})," service to send API calls to the ",(0,t.jsx)(n.code,{children:"openai-access-gateway"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-diff",children:' services:\n   app:\n     ports:\n       - 3000:3000\n     environment:\n       OPENAI_API_KEY:\n+      OPENAI_BASE_URL: "http://llm/api/v1"\n     healthcheck:\n       test: ["CMD", "curl", "-f", "http://localhost:3000/"]\n'})}),"\n",(0,t.jsx)(n.p,{children:"Now, all OpenAI traffic will be routed through your gateway service and onto AWS Bedrock."}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"selecting-a-model",children:"Selecting a Model"}),"\n",(0,t.jsx)(n.p,{children:"You should configure your application to specify the model you want to use."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-diff",children:' services:\n   app:\n     ports:\n       - 3000:3000\n     environment:\n       OPENAI_API_KEY:\n       OPENAI_BASE_URL: "http://llm/api/v1"\n+      MODEL: "anthropic.claude-3-sonnet-20240229-v1:0"\n     healthcheck:\n       test: ["CMD", "curl", "-f", "http://localhost:3000/"]\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Choose the correct ",(0,t.jsx)(n.code,{children:"MODEL"})," depending on which cloud provider you are using."]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Choosing the Right Model"})}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["For ",(0,t.jsx)(n.strong,{children:"AWS Bedrock"}),", use a Bedrock model ID (e.g., ",(0,t.jsx)(n.code,{children:"anthropic.claude-3-sonnet-20240229-v1:0"}),"). ",(0,t.jsx)(n.a,{href:"https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",children:"See available Bedrock models"}),"."]}),"\n"]})]}),"\n",(0,t.jsxs)(n.p,{children:["Alternatively, Defang supports ",(0,t.jsx)(n.a,{href:"/docs/concepts/managed-llms/openai-access-gateway/#model-mapping",children:"model mapping"})," through the ",(0,t.jsx)(n.a,{href:"https://github.com/DefangLabs/openai-access-gateway",children:"openai-access-gateway"}),". This takes a model with a Docker naming convention (e.g. ",(0,t.jsx)(n.code,{children:"ai/llama3.3"}),") and maps it to\nthe closest equivalent on the target platform. If no such match can be found, a fallback can be defined to use a known existing model (e.g. ",(0,t.jsx)(n.code,{children:"ai/mistral"}),"). These environment\nvariables are ",(0,t.jsx)(n.code,{children:"USE_MODEL_MAPPING"})," (default to true) and ",(0,t.jsx)(n.code,{children:"FALLBACK_MODEL"})," (no default), respectively."]}),"\n",(0,t.jsx)(n.h2,{id:"complete-example-compose-file",children:"Complete Example Compose File"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'services:\n  app:\n    build:\n      context: .\n    ports:\n      - 3000:3000\n    environment:\n      OPENAI_API_KEY:\n      OPENAI_BASE_URL: "http://llm/api/v1"\n      MODEL: "anthropic.claude-3-sonnet-20240229-v1:0"\n    healthcheck:\n      test: ["CMD", "curl", "-f", "http://localhost:3000/"]\n\n  llm:\n    image: defangio/openai-access-gateway\n    x-defang-llm: true\n    ports:\n      - target: 80\n        published: 80\n        mode: host\n    environment:\n      - OPENAI_API_KEY\n      - REGION\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"environment-variable-matrix",children:"Environment Variable Matrix"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Variable"}),(0,t.jsx)(n.th,{children:"AWS Bedrock"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"REGION"})}),(0,t.jsx)(n.td,{children:"Required"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"MODEL"})}),(0,t.jsxs)(n.td,{children:["Bedrock model ID or Docker model name, for example ",(0,t.jsx)(n.code,{children:"meta.llama3-3-70b-instruct-v1:0"})," or ",(0,t.jsx)(n.code,{children:"ai/llama3.3"})]})]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.p,{children:"You now have a single app that can:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Talk to ",(0,t.jsx)(n.strong,{children:"AWS Bedrock"})]}),"\n",(0,t.jsx)(n.li,{children:"Use the same OpenAI-compatible client code"}),"\n",(0,t.jsx)(n.li,{children:"Easily switch between models or cloud providers by changing a few environment variables"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}}}]);